---
# There is a problem with kubelet volume mounting
#  See https://github.com/kubernetes/kubernetes/pull/71663
#  Workaround here requires manually copying data into mounted
#  path after installation completes
- name: TODO remove when bug 1294 is fixed - unmount kubelet vol
  mount:
    fstype: ext4
    path: /var/lib/kubelet
    src: /dev/mapper/luks-kubelet
    state: unmounted

- name: Reset Kubernetes component
  command: kubeadm reset --force --cri-socket unix:///var/run/cri-docker.sock
  register: reset_cluster

- name: Set kubeadm configuration
  copy:
    dest: /etc/kubernetes/kubeadm-config.yaml
    content: |
      ---
      # This file generated by ansible
      #
      apiVersion: kubeadm.k8s.io/v1beta4
      kind: InitConfiguration
      bootstrapTokens:
      - token: {{ vault_k8s.join_token }}
        ttl: 1h0m0s
        usages:
        - signing
        - authentication
        groups:
        - system:bootstrappers:kubeadm:default-node-token
      localAPIEndpoint:
        advertiseAddress: {{ k8s.cplane_vip }}
        bindPort: 6443
      nodeRegistration:
        criSocket: unix:///var/run/cri-dockerd.sock
        # TODO: might be able to retire cri-dockerd
        #  probably need to update /etc/containerd/config.toml
        # criSocket: unix:///run/containerd/containerd.sock
        imagePullPolicy: IfNotPresent
        imagePullSerial: true
        name: {{ ansible_fqdn }}
        taints:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
      # Some default values, uncomment and modify as desired
      # timeouts:
      #   controlPlaneComponentHealthCheck: 4m0s
      #   discovery: 5m0s
      #   etcdAPICall: 2m0s
      #   kubeletHealthCheck: 4m0s
      #   kubernetesAPICall: 1m0s
      #   tlsBootstrap: 5m0s
      #   upgradeManifests: 5m0s
      ---
      apiVersion: kubeadm.k8s.io/v1beta4
      kind: ClusterConfiguration
      apiServer:
        certSANs:
        - {{ k8s.cplane_hostip }}
        - {{ k8s.cplane_vip }}
        extraArgs:
        - name: oidc-issuer-url
          value: {{ oidc.issuer_url }}
        - name: oidc-client-id
          value: {{ oidc.client_id }}
        - name: oidc-username-claim
          value: {{ oidc.username_claim }}
        - name: oidc-groups-claim
          value: {{ oidc.groups_claim }}
        - name: oidc-username-prefix
          value: {{ oidc.username_prefix }}
        - name: oidc-groups-prefix
          value : {{ oidc.username_prefix }}
      dns:
        # Workaround for bug 112131; never got fixed as of k8s 1.31:
        # https://github.com/kubernetes/kubernetes/issues/112131
        imageRepository: registry.k8s.io/coredns
        imageTag: {{ k8s.coredns_version }}
      imageRepository: registry.k8s.io
      kubernetesVersion: v{{ k8s.version }}
      networking:
        dnsDomain: cluster.local
        podSubnet: {{ k8s.pod_network }}
        serviceSubnet: {{ k8s.service_network }}
      # Some default values, uncomment and modify as desired
      # caCertificateValidityPeriod: 87600h0m0s
      # certificateValidityPeriod: 8760h0m0s
      # certificatesDir: /etc/kubernetes/pki
      # clusterName: kubernetes
      # controllerManager: {}
      # encryptionAlgorithm: RSA-2048
      # etcd:
      #   local:
      #     dataDir: /var/lib/etcd

- name: Init Kubernetes cluster
  command: kubeadm init --config /etc/kubernetes/kubeadm-config.yaml
  register: init_cluster
  when: reset_cluster is succeeded
